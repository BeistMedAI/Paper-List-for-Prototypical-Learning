# üåü Paper List for Prototypical Learning - [Junhao Jia](https://BeistMedAI.github.io/)

<div align="center">
  

[![](https://img.shields.io/github/stars/BeistMedAI/Paper-List-for-Prototypical-Learning)](https://github.com/BeistMedAI/Paper-List-for-Prototypical-Learning)
[![](https://img.shields.io/github/forks/BeistMedAI/Paper-List-for-Prototypical-Learning)](https://github.com/BeistMedAI/Paper-List-for-Prototypical-Learning)
[![](https://img.shields.io/github/issues/BeistMedAI/Paper-List-for-Prototypical-Learning)](https://github.com/BeistMedAI/Paper-List-for-Prototypical-Learning/issues)[![](https://img.shields.io/github/license/BeistMedAI/Paper-List-for-Prototypical-Learning)](https://github.com/BeistMedAI/Paper-List-for-Prototypical-Learning/blob/main/LICENSE) 
  
</div>

**ü¶â Contributors: [Junhao Jia (23' HDU Undergraduate)](https://github.com/BeistMedAI), [Yifei Sun (22' HDU-ITMO Undergraduate)](https://diaoquesang.github.io/), [Shuo Jiang (23' HDU Undergraduate)](https://github.com/JSLiam94), [Hanwen Zheng (23' HDU Undergraduate)](https://github.com/Zhenghanwen-zhw), [Yuting Shi (23' HDU Undergraduate)](https://github.com/sytttttttt)**

**üì¶ Other resources: [Paper-List-for-Medical-Anomaly-Detection](https://github.com/diaoquesang/Paper-List-for-Medical-Anomaly-Detection).**

### Welcome to join us by contacting: 23080631@hdu.edu.cn.

<div>
<img src="https://github.com/diaoquesang/Paper-List-for-Medical-Anomaly-Detection/blob/main/logos/HDU.png" height="45px" href="https://www.hdu.edu.cn/">
<img src="https://github.com/diaoquesang/Paper-List-for-Medical-Anomaly-Detection/blob/main/logos/ITMO.jpg" height="45px" href="https://en.itmo.ru/">
<img src="https://github.com/BeistMedAI/Paper-List-for-Prototypical-Learning/blob/main/logos/SRIBD.png" height="45px" href="https://www.sribd.cn/">
</div>

## üìá Contents
- [üìö Overview](#s1)
- [‚úèÔ∏è Tips](#s2)
- [üïê 1. Prototype Learning for Image Classification](#s3)
- [üïë 2. Prototype Learning for Medical Image Classification](#s4)
- [ü•∞ Star History](#s5)

## üìö Overview

## ‚úèÔ∏è Tips
<div id = "s2"></div>

- :octocat: : Code
- ‚ö†Ô∏è : Remark

## üïê 1. Prototype Learning for Image Classification
<div id = "s3"></div>

- [[2017-NIPS]](https://proceedings.neurips.cc/paper_files/paper/2017/file/cb8da6767461f2812ae4290eac7cbc42-Paper.pdf) **Prototypical networks for few-shot learning** [:octocat:](https://github.com/jakesnell/prototypical-networks)

- [Abstract] We propose Prototypical Networks for the problem of few-shot classification, where a classifier must generalize to new classes not seen in the training set, given only a small number of examples of each new class. Prototypical Networks learn a metric space in which classification can be performed by computing distances to prototype representations of each class. Compared to recent approaches for few-shot learning, they reflect a simpler inductive bias that is beneficial in this limited-data regime, and achieve excellent results. We provide an analysis showing that some simple design decisions can yield substantial improvements over recent approaches involving complicated architectural choices and meta-learning. We further extend Prototypical Networks to zero-shot learning and achieve state-of-the-art results on the CU-Birds dataset.

<pre>
@article{snell2017prototypical,
  title={Prototypical networks for few-shot learning},
  author={Snell, Jake and Swersky, Kevin and Zemel, Richard},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
</pre>

![alt text](images/image.png)

- [[2019-NIPS]](https://proceedings.neurips.cc/paper/2019/file/adf7ee2dcf142b0e11888e72b43fcb75-Paper.pdf) **This looks like that: deep learning for interpretable image recognition** [:octocat:](https://github.com/cfchen-duke/ProtoPNet)

<pre>
@article{chen2019looks,
  title={This looks like that: deep learning for interpretable image recognition},
  author={Chen, Chaofan and Li, Oscar and Tao, Daniel and Barnett, Alina and Rudin, Cynthia and Su, Jonathan K},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}
</pre>

![alt text](images/image-1.png)

- [[2019-AAAI]](https://ojs.aaai.org/index.php/HCOMP/article/view/5265) **Interpretable Image Recognition with Hierarchical Prototypes** [:octocat:](https://github.com/peterbhase/interpretable-image)

<pre>
@inproceedings{hase2019interpretable,
  title={Interpretable image recognition with hierarchical prototypes},
  author={Hase, Peter and Chen, Chaofan and Li, Oscar and Rudin, Cynthia},
  booktitle={Proceedings of the AAAI Conference on Human Computation and Crowdsourcing},
  volume={7},
  pages={32--40},
  year={2019}
}
</pre>

![alt text](images/image-2.png)

- [[2021-ICML]](https://arxiv.org/pdf/2105.02968) **This Looks Like That... Does it_Shortcomings of Latent Space Prototype Interpretability in Deep Networks** [:octocat:](https://github.com/fanconic/this-does-not-look-like-that)

<pre>
@misc{hoffmann2021looks,
    title={This Looks Like That... Does it? Shortcomings of Latent Space Prototype Interpretability in Deep Networks}, 
    author={Adrian Hoffmann and Claudio Fanconi and Rahul Rade and Jonas Kohler},
    year={2021},
    booktitle={ICML 2021 Workshop on Theoretic Foundation, Criticism, and Application Trend of Explainable AI},
}
</pre>

![alt text](images/image-3.png)

- [[2022-ECCV]](https://arxiv.org/pdf/2112.03184) **HIVE: Evaluating the human interpretability of visual explanations** [:octocat:](https://github.com/princetonvisualai/HIVE)

<pre>
@inproceedings{kim2022hive,
  title={HIVE: Evaluating the human interpretability of visual explanations},
  author={Kim, Sunnie SY and Meister, Nicole and Ramaswamy, Vikram V and Fong, Ruth and Russakovsky, Olga},
  booktitle={European Conference on Computer Vision},
  pages={280--298},
  year={2022},
  organization={Springer}
}
</pre>

![alt text](images/image-4.png)

- [[2022-ECCV]](https://arxiv.org/pdf/2112.02902) **Interpretable image classification with differentiable prototypes assignment** [:octocat:](https://github.com/gmum/ProtoPool)

<pre>
@inproceedings{rymarczyk2022interpretable,
  title={Interpretable image classification with differentiable prototypes assignment},
  author={Rymarczyk, Dawid and Struski, {\L}ukasz and G{\'o}rszczak, Micha{\l} and Lewandowska, Koryna and Tabor, Jacek and Zieli{\'n}ski, Bartosz},
  booktitle={European Conference on Computer Vision},
  pages={351--368},
  year={2022},
  organization={Springer}
}
</pre>

![alt text](images/image-5.png)

- [[2023-CVPR]](https://openaccess.thecvf.com/content/CVPR2023/papers/Nauta_PIP-Net_Patch-Based_Intuitive_Prototypes_for_Interpretable_Image_Classification_CVPR_2023_paper.pdf) **Pip-net: Patch-based intuitive prototypes for interpretable image classification** [:octocat:](https://github.com/M-Nauta/PIPNet)

<pre>
@inproceedings{nauta2023pip,
  title={Pip-net: Patch-based intuitive prototypes for interpretable image classification},
  author={Nauta, Meike and Schl{\"o}tterer, J{\"o}rg and Van Keulen, Maurice and Seifert, Christin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2744--2753},
  year={2023}
}
</pre>

![alt text](images/image-6.png)

- [[2023-ICCV]](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_Support_and_Trivial_Prototypes_for_Interpretable_Image_Classification_ICCV_2023_paper.pdf) **Learning support and trivial prototypes for interpretable image classification**[:octocat:](https://github.com/cwangrun/ST-ProtoPNet)

<pre>
@inproceedings{wang2023learning,
  title={Learning support and trivial prototypes for interpretable image classification},
  author={Wang, Chong and Liu, Yuyuan and Chen, Yuanhong and Liu, Fengbei and Tian, Yu and McCarthy, Davis and Frazer, Helen and Carneiro, Gustavo},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2062--2072},
  year={2023}
}
</pre>

![alt text](images/image-7.png)

- [[2023-ICCV]](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Evaluation_and_Improvement_of_Interpretability_for_Self-Explainable_Part-Prototype_Networks_ICCV_2023_paper.pdf) **Evaluation and improvement of interpretability for self-explainable part-prototype networks** 

<pre>
@inproceedings{huang2023evaluation,
  title={Evaluation and improvement of interpretability for self-explainable part-prototype networks},
  author={Huang, Qihan and Xue, Mengqi and Huang, Wenqi and Zhang, Haofei and Song, Jie and Jing, Yongcheng and Song, Mingli},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2011--2020},
  year={2023}
}
</pre>

![alt text](images/image-8.png)

- [[2023-NIPS]](https://proceedings.neurips.cc/paper_files/paper/2023/file/7b76eea0c3683e440c3d362620f578cd-Paper-Conference.pdf) **This Looks Like Those_Illuminating Prototypical Concepts Using Multiple Visualizations** [:octocat:](https://github.com/Henrymachiyu/This-looks-like-those_ProtoConcepts)

<pre>
@article{ma2023looks,
  title={This looks like those: Illuminating prototypical concepts using multiple visualizations},
  author={Ma, Chiyu and Zhao, Brandon and Chen, Chaofan and Rudin, Cynthia},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={39212--39235},
  year={2023}
}
</pre>

![alt text](images/image-9.png)

- [[2024-WACV]](https://openaccess.thecvf.com/content/WACV2024/papers/Carmichael_Pixel-Grounded_Prototypical_Part_Networks_WACV_2024_paper.pdf) **Pixel-grounded prototypical part networks** [:octocat:](https://github.com/mpmath/mpmath)

<pre>
@inproceedings{carmichael2024pixel,
  title={Pixel-grounded prototypical part networks},
  author={Carmichael, Zachariah and Lohit, Suhas and Cherian, Anoop and Jones, Michael J and Scheirer, Walter J},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={4768--4779},
  year={2024}
}
</pre>

![alt text](images/image-10.png)

- [[2024-AAAI]](https://ojs.aaai.org/index.php/AAAI/article/view/30154) **Interpretability benchmark for evaluating spatial misalignment of prototypical parts explanations** 

<pre>
@inproceedings{sacha2024interpretability,
  title={Interpretability benchmark for evaluating spatial misalignment of prototypical parts explanations},
  author={Sacha, Miko{\l}aj and Jura, Bartosz and Rymarczyk, Dawid and Struski, {\L}ukasz and Tabor, Jacek and Zieli{\'n}ski, Bartosz},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={19},
  pages={21563--21573},
  year={2024}
}
</pre>

![alt text](images/image-11.png)

- [[2024-AAAI]](https://ojs.aaai.org/index.php/AAAI/article/view/30109) **On the concept trustworthiness in concept bottleneck models** [:octocat:](https://github.com/hqhQAQ/ProtoCBM)

<pre>
@inproceedings{huang2024concept,
  title={On the concept trustworthiness in concept bottleneck models},
  author={Huang, Qihan and Song, Jie and Hu, Jingwen and Zhang, Haofei and Wang, Yong and Song, Mingli},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={19},
  pages={21161--21168},
  year={2024}
}
</pre>

![alt text](images/image-12.png)

- [[2024-ECCV]](https://arxiv.org/pdf/2407.12200) **This Probably Looks Exactly Like That: An Invertible Prototypical Network** [:octocat:](https://github.com/craymichael/ProtoFlow)

<pre>
@inproceedings{carmichael2024probably,
  title={This probably looks exactly like that: An invertible prototypical network},
  author={Carmichael, Zachariah and Redgrave, Timothy and Cedre, Daniel Gonzalez and Scheirer, Walter J},
  booktitle={European Conference on Computer Vision},
  pages={221--240},
  year={2024},
  organization={Springer}
}
</pre>

![alt text](images/image-13.png)

- [[2024-NIPS]](https://proceedings.neurips.cc/paper_files/paper/2024/file/48dfc849640344e2d58df0b5bb78c33b-Paper-Conference.pdf) **Interpretable Image Classification with Adaptive Prototype-based Vision Transformers** [:octocat:](https://github.com/Henrymachiyu/ProtoViT)

<pre>
@inproceedings{ma2024interpretable,
  title={Interpretable Image Classification with Adaptive Prototype-based Vision Transformers},
  author={Ma, Chiyu and Donnelly, Jon and Liu, Wenjun and Vosoughi, Soroush and Rudin, Cynthia and Chen, Chaofan},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024}
}
</pre>

![alt text](images/image-14.png)

- [[2024-CVPR]](https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_MCPNet_An_Interpretable_Classifier_via_Multi-Level_Concept_Prototypes_CVPR_2024_paper.pdf) **Mcpnet: An interpretable classifier via multi-level concept prototypes** [:octocat:](https://github.com/NVlabs/MCPNet)

<pre>
@inproceedings{wang2024mcpnet,
  title={Mcpnet: An interpretable classifier via multi-level concept prototypes},
  author={Wang, Bor-Shiun and Wang, Chien-Yi and Chiu, Wei-Chen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10885--10894},
  year={2024}
}
</pre>

![alt text](images/image-15.png)

- [[2024-arXiv]](https://arxiv.org/pdf/2406.14675) **This looks better than that: Better interpretable models with protopnext**

<pre>
@article{willard2024looks,
  title={This looks better than that: Better interpretable models with protopnext},
  author={Willard, Frank and Moffett, Luke and Mokel, Emmanuel and Donnelly, Jon and Guo, Stark and Yang, Julia and Kim, Giyoung and Barnett, Alina Jade and Rudin, Cynthia},
  journal={arXiv preprint arXiv:2406.14675},
  year={2024}
}
</pre>

![alt text](images/image-16.png)

- [[2025-ICASSP]](https://ieeexplore.ieee.org/abstract/document/10890753) **Prototypical Part Transformer for Interpretable Image Recognition**

<pre>
@inproceedings{yu2025prototypical,
  title={Prototypical Part Transformer for Interpretable Image Recognition},
  author={Yu, Anni and Yang, Yu-Bin},
  booktitle={ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2025},
  organization={IEEE}
}
</pre>

![alt text](images/image-17.png)

- [[2025-AAAI]](https://ojs.aaai.org/index.php/AAAI/article/view/32173) **ProtoArgNet: Interpretable Image Classification with Super-Prototypes and Argumentation**[:octocat:](https://github.com/H-Ayoobi/ProtoArgNet_AAAI)

<pre>
@inproceedings{ayoobi2025protoargnet,
  title={ProtoArgNet: Interpretable Image Classification with Super-Prototypes and Argumentation},
  author={Ayoobi, Hamed and Potyka, Nico and Toni, Francesca},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={39},
  number={2},
  pages={1791--1799},
  year={2025}
}
</pre>

![alt text](images/image-18.png)

- [[2025-PR]](https://www.sciencedirect.com/science/article/pii/S0031320324006526) **Characteristic discriminative prototype network with detailed interpretation for classification**

<pre>
@article{wen2025characteristic,
  title={Characteristic discriminative prototype network with detailed interpretation for classification},
  author={Wen, Jiajun and Kong, Heng and Lai, Zhihui and Zhu, Zhijie},
  journal={Pattern Recognition},
  volume={157},
  pages={110901},
  year={2025},
  publisher={Elsevier}
}
</pre>

![alt text](images/image-19.png)

- [[2025-TPAMI]](https://ieeexplore.ieee.org/abstract/document/10982376) **Mixture of gaussian-distributed prototypes with generative modelling for interpretable and trustworthy image recognition**[:octocat:](https://github.com/cwangrun/MGProto)

<pre>
@article{wang2025mixture,
  title={Mixture of gaussian-distributed prototypes with generative modelling for interpretable and trustworthy image recognition},
  author={Wang, Chong and Chen, Yuanhong and Liu, Fengbei and Liu, Yuyuan and McCarthy, Davis James and Frazer, Helen and Carneiro, Gustavo},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2025},
  publisher={IEEE}
}
</pre>

![alt text](images/image-20.png)

## üïê 2. Prototype Learning for Medical Image Classification
<div id = "s4"></div>

üïê (1) Ophthalmology

- [[2022-MICCAI]](https://arxiv.org/pdf/2208.00457) **INSightR-Net: interpretable neural network for regression using similarity-based comparisons to prototypical examples** [:octocat:](https://github.com/lindehesse/INSightR-Net)

<pre>
@inproceedings{hesse2022insightr,
  title={INSightR-Net: interpretable neural network for regression using similarity-based comparisons to prototypical examples},
  author={Hesse, Linde S and Namburete, Ana IL},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={502--511},
  year={2022},
  organization={Springer}
}
</pre>

![alt text](images/image-21.png)

- [[2024-MICCAI]](https://arxiv.org/pdf/2406.15168) **This actually looks like that: Proto-BagNets for local and global interpretability-by-design** [:octocat:](https://github.com/kdjoumessi/Proto-BagNets)

<pre>
@inproceedings{djoumessi2024actually,
  title={This actually looks like that: Proto-BagNets for local and global interpretability-by-design},
  author={Djoumessi, Kerol and Bah, Bubacarr and K{\"u}hlewein, Laura and Berens, Philipp and Koch, Lisa},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={718--728},
  year={2024},
  organization={Springer}
}
</pre>

![alt text](images/image-22.png)

- [[2025-JBHI]](https://ieeexplore.ieee.org/abstract/document/10955117) **Progressive Mining and Dynamic Distillation of Hierarchical Prototypes for Disease Classification and Localisation** [:octocat:](https://github.com/cwangrun/HierProtoPNet)

<pre>
@article{wang2025progressive,
  title={Progressive Mining and Dynamic Distillation of Hierarchical Prototypes for Disease Classification and Localisation},
  author={Wang, Chong and Liu, Fengbei and Chen, Yuanhong and Kwok, Chun Fung and Elliott, Michael and Pena-Solorzano, Carlos and McCarthy, Davis James and Frazer, Helen and Carneiro, Gustavo},
  journal={IEEE Journal of Biomedical and Health Informatics},
  year={2025},
  publisher={IEEE}
}
</pre>

![alt text](images/image-23.png)

üïê (2) Cancer

- [[2023-JBHI]](https://ieeexplore.ieee.org/abstract/document/10290723) **Interpretable inference and classification of tissue types in histological colorectal cancer slides based on ensembles adaptive boosting prototype tree** 

<pre>
@article{liang2023interpretable,
  title={Interpretable inference and classification of tissue types in histological colorectal cancer slides based on ensembles adaptive boosting prototype tree},
  author={Liang, Meiyan and Wang, Ru and Liang, Jianan and Wang, Lin and Li, Bo and Jia, Xiaojun and Zhang, Yu and Chen, Qinghui and Zhang, Tianyi and Zhang, Cunlin},
  journal={IEEE Journal of Biomedical and Health Informatics},
  volume={27},
  number={12},
  pages={6006--6017},
  year={2023},
  publisher={IEEE}
}
</pre>

![alt text](images/image-25.png)

- [[2023-ECAI]](https://arxiv.org/pdf/2307.10404) **Interpreting and correcting medical image classification with pip-net** 

<pre>
@inproceedings{nauta2023interpreting,
  title={Interpreting and correcting medical image classification with pip-net},
  author={Nauta, Meike and Hegeman, Johannes H and Geerdink, Jeroen and Schl{\"o}tterer, J{\"o}rg and Keulen, Maurice van and Seifert, Christin},
  booktitle={European Conference on Artificial Intelligence},
  pages={198--215},
  year={2023},
  organization={Springer}
}
</pre>

![alt text](images/image-26.png)

- [[2023-TMI]](https://ieeexplore.ieee.org/abstract/document/10225391) **An Interpretable and Accurate Deep-Learning Diagnosis Framework Modeled With Fully and Semi-Supervised Reciprocal Learning** [:octocat:](https://github.com/sendyma/Medical-XAI)

<pre>
@article{wang2023interpretable,
  title={An Interpretable and Accurate Deep-Learning Diagnosis Framework Modeled With Fully and Semi-Supervised Reciprocal Learning},
  author={Wang, Chong and Chen, Yuanhong and Liu, Fengbei and Elliott, Michael and Kwok, Chun Fung and Pena-Solorzano, Carlos and Frazer, Helen and McCarthy, Davis James and Carneiro, Gustavo},
  journal={IEEE transactions on medical imaging},
  volume={43},
  number={1},
  pages={392--404},
  year={2023},
  publisher={IEEE}
}
</pre>

![alt text](images/image-27.png)

- [[2023-MICCAI]](https://arxiv.org/pdf/2310.15741) **Interpretable medical image classification using prototype learning and privileged information** [:octocat:](https://github.com/XRad-Ulm/Proto-Caps)

<pre>
@inproceedings{gallee2023interpretable,
  title={Interpretable medical image classification using prototype learning and privileged information},
  author={Gall{\'e}e, Luisa and Beer, Meinrad and G{\"o}tz, Michael},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={435--445},
  year={2023},
  organization={Springer}
}
</pre>

![alt text](images/image-28.png)

- [[2024-MICCAI]](https://papers.miccai.org/miccai-2024/paper/1022_paper.pdf) **Pamil: Prototype attention-based multiple instance learning for whole slide image classification** [:octocat:](https://github.com/Jiashuai-Liu/PAMIL)

<pre>
@inproceedings{liu2024pamil,
  title={Pamil: Prototype attention-based multiple instance learning for whole slide image classification},
  author={Liu, Jiashuai and Mao, Anyu and Niu, Yi and Zhang, Xianli and Gong, Tieliang and Li, Chen and Gao, Zeyu},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={362--372},
  year={2024},
  organization={Springer}
}
</pre>

![alt text](images/image-29.png)

- [[2024-arXiv]](https://arxiv.org/pdf/2402.01410) **XAI for Skin Cancer Detection with Prototypes and Non-Expert Supervision** [:octocat:](https://github.com/MiguelC23/XAI-Skin-Cancer-Detection-A-Prototype-Based-Deep-Learning-Architecture-with-Non-Expert-Supervision)

<pre>
@article{correia2024xai,
  title={XAI for Skin Cancer Detection with Prototypes and Non-Expert Supervision},
  author={Correia, Miguel and Bissoto, Alceu and Santiago, Carlos and Barata, Catarina},
  journal={arXiv preprint arXiv:2402.01410},
  year={2024}
}
</pre>

![alt text](images/image-30.png)

üïê (3) Alzheimer‚Äôs disease detection
- [[2023-NeuroImage]](https://www.sciencedirect.com/science/article/pii/S1053811923002197) **Estimating explainable Alzheimer's disease likelihood map via clinically-guided prototype learning** [:octocat:](https://github.com/ku-milab/XADLiME)

<pre>
@article{mulyadi2023estimating,
  title={Estimating explainable Alzheimer‚Äôs disease likelihood map via clinically-guided prototype learning},
  author={Mulyadi, Ahmad Wisnu and Jung, Wonsik and Oh, Kwanseok and Yoon, Jee Seok and Lee, Kun Ho and Suk, Heung-Il},
  journal={NeuroImage},
  volume={273},
  pages={120073},
  year={2023},
  publisher={Elsevier}
}
</pre>

![alt text](images/image-31.png)

- [[2023-IPMI]](https://arxiv.org/pdf/2303.07125) **Don't panic: Prototypical additive neural network for interpretable classification of alzheimer's disease** [:octocat:](https://github.com/ai-med/PANIC)

<pre>
@inproceedings{wolf2023don,
  title={Don‚Äôt panic: Prototypical additive neural network for interpretable classification of alzheimer‚Äôs disease},
  author={Wolf, Tom Nuno and P{\"o}lsterl, Sebastian and Wachinger, Christian},
  booktitle={International Conference on Information Processing in Medical Imaging},
  pages={82--94},
  year={2023},
  organization={Springer}
}
</pre>

![alt text](images/image-32.png)

- [[2024-MICCAI]](https://arxiv.org/pdf/2403.18328) **Pipnet3d: Interpretable detection of alzheimer in mri scans** 
<pre>
@inproceedings{de2024pipnet3d,
  title={Pipnet3d: Interpretable detection of alzheimer in mri scans},
  author={De Santi, Lisa Anita and Schl{\"o}tterer, J{\"o}rg and Scheschenja, Michael and Wessendorf, Joel and Nauta, Meike and Positano, Vincenzo and Seifert, Christin},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={69--78},
  year={2024},
  organization={Springer}
}
</pre>

![alt text](images/image-33.png)

üïê (4) Mammography

- [[2021-nature machine intelligence]](https://arxiv.org/pdf/2103.12308) **A case-based interpretable deep learning model for classification of mass lesions in digital mammography** [:octocat:](https://github.com/alinajadebarnett/iaiabl)

<pre>
@article{barnett2021case,
  title={A case-based interpretable deep learning model for classification of mass lesions in digital mammography},
  author={Barnett, Alina Jade and Schwartz, Fides Regina and Tao, Chaofan and Chen, Chaofan and Ren, Yinhao and Lo, Joseph Y and Rudin, Cynthia},
  journal={Nature Machine Intelligence},
  volume={3},
  number={12},
  pages={1061--1070},
  year={2021},
  publisher={Nature Publishing Group UK London}
}
</pre>

![alt text](images/image-34.png)

- [[2022-MICCAI]](https://arxiv.org/pdf/2209.12420) **Knowledge distillation to ensemble global and interpretable prototype-based mammogram classification models** 

<pre>
@inproceedings{wang2022knowledge,
  title={Knowledge distillation to ensemble global and interpretable prototype-based mammogram classification models},
  author={Wang, Chong and Chen, Yuanhong and Liu, Yuyuan and Tian, Yu and Liu, Fengbei and McCarthy, Davis J and Elliott, Michael and Frazer, Helen and Carneiro, Gustavo},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={14--24},
  year={2022},
  organization={Springer}
}
</pre>

![alt text](images/image-24.png)

- [[2024-CVPR Workshop]](https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/papers/Yang_FPN-IAIA-BL_A_Multi-Scale_Interpretable_Deep_Learning_Model_for_Classification_of_CVPRW_2024_paper.pdf) **FPN-IAIA-BL: A Multi-Scale Interpretable Deep Learning Model for Classification of Mass Margins in Digital Mammography** 

<pre>
@inproceedings{yang2024fpn,
  title={FPN-IAIA-BL: A Multi-Scale Interpretable Deep Learning Model for Classification of Mass Margins in Digital Mammography},
  author={Yang, Julia and Barnett, Alina Jade and Donnelly, Jon and Kishore, Satvik and Fang, Jerry and Schwartz, Fides Regina and Chen, Chaofan and Lo, Joseph Y and Rudin, Cynthia},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5003--5009},
  year={2024}
}
</pre>

![alt text](images/image-35.png)

üïê (5) Chest X-ray

- [[2021-CVPR]](https://openaccess.thecvf.com/content/CVPR2021/papers/Kim_XProtoNet_Diagnosis_in_Chest_Radiography_With_Global_and_Local_Explanations_CVPR_2021_paper.pdf) **XProtoNet: diagnosis in chest radiography with global and local explanations** 

<pre>
@inproceedings{kim2021xprotonet,
  title={XProtoNet: diagnosis in chest radiography with global and local explanations},
  author={Kim, Eunji and Kim, Siwon and Seo, Minji and Yoon, Sungroh},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={15719--15728},
  year={2021}
}
</pre>

![alt text](images/image-36.png)

- [[2024-ISBI]](https://ieeexplore.ieee.org/abstract/document/10635182) **Explainable transformer prototypes for medical diagnoses** [:octocat:](http://www.github.com/NUBagcilab/r2r_proto)

<pre>
@inproceedings{demir2024explainable,
  title={Explainable transformer prototypes for medical diagnoses},
  author={Demir, Ugur and Jha, Debesh and Zhang, Zheyuan and Keles, Elif and Allen, Bradley and Katsaggelos, Aggelos K and Bagci, Ulas},
  booktitle={2024 IEEE International Symposium on Biomedical Imaging (ISBI)},
  pages={1--5},
  year={2024},
  organization={IEEE}
}
</pre>

![alt text](images/image-37.png)

- [[2025-TMI]](https://ieeexplore.ieee.org/abstract/document/10887396) **Cross-and Intra-image Prototypical Learning for Multi-label Disease Diagnosis and Interpretation** [:octocat:](https://github.com/cwangrun/CIPL)

<pre>
@article{wang2025cross,
  title={Cross-and Intra-image Prototypical Learning for Multi-label Disease Diagnosis and Interpretation},
  author={Wang, Chong and Liu, Fengbei and Chen, Yuanhong and Frazer, Helen and Carneiro, Gustavo},
  journal={IEEE Transactions on Medical Imaging},
  year={2025},
  publisher={IEEE}
}
</pre>

![alt text](images/image-38.png)

üïê (6) Echocardiography

- [[2023-MICCAI]](https://arxiv.org/pdf/2307.14433) **Protoasnet: Dynamic prototypes for inherently interpretable and uncertainty-aware aortic stenosis classification in echocardiography** [:octocat:](https://github.com/hooman007/ProtoASNet)

<pre>
@inproceedings{vaseli2023protoasnet,
  title={Protoasnet: Dynamic prototypes for inherently interpretable and uncertainty-aware aortic stenosis classification in echocardiography},
  author={Vaseli, Hooman and Gu, Ang Nan and Ahmadi Amiri, S Neda and Tsang, Michael Y and Fung, Andrea and Kondori, Nima and Saadat, Armin and Abolmaesumi, Purang and Tsang, Teresa SM},
  booktitle={International conference on medical image computing and computer-assisted intervention},
  pages={368--378},
  year={2023},
  organization={Springer}
}
</pre>

![alt text](images/image-39.png)

- [[2025-MedIA]](https://www.sciencedirect.com/science/article/pii/S1361841525001471) **ProtoASNet: Comprehensive evaluation and enhanced performance with uncertainty estimation for Aortic stenosis classification in echocardiography** [:octocat:](https://github.com/hooman007/ProtoASNet)

<pre>
@article{gu2025protoasnet,
  title={ProtoASNet: Comprehensive evaluation and enhanced performance with uncertainty estimation for Aortic stenosis classification in echocardiography},
  author={Gu, Ang Nan and Vaseli, Hooman and Tsang, Michael Y and Wu, Victoria and Amiri, S Neda Ahmadi and Kondori, Nima and Fung, Andrea and Tsang, Teresa SM and Abolmaesumi, Purang},
  journal={Medical Image Analysis},
  pages={103600},
  year={2025},
  publisher={Elsevier}
}
</pre>

![alt text](images/image-40.png)

üïê (7) COVID-19

- [[2022-NN]](https://www.sciencedirect.com/science/article/pii/S0893608022001125) **Think positive: An interpretable neural network for image recognition** 

<pre>
@article{singh2022think,
  title={Think positive: An interpretable neural network for image recognition},
  author={Singh, Gurmail},
  journal={Neural Networks},
  volume={151},
  pages={178--189},
  year={2022},
  publisher={Elsevier}
}
</pre>

![alt text](images/image-41.png)

üïê (8) Heart disease

- [[2025-MIA]](https://www.sciencedirect.com/science/article/pii/S1361841525000854) **Graph-based prototype inverse-projection for identifying cortical sulcal pattern abnormalities in congenital heart disease** [:octocat:](https://github.com/hookhy/surfacepip)

<pre>
@article{kwon2025graph,
  title={Graph-based prototype inverse-projection for identifying cortical sulcal pattern abnormalities in congenital heart disease},
  author={Kwon, Hyeokjin and Son, Seungyeon and Morton, Sarah U and Wypij, David and Cleveland, John and Rollins, Caitlin K and Huang, Hao and Goldmuntz, Elizabeth and Panigrahy, Ashok and Thomas, Nina H and others},
  journal={Medical Image Analysis},
  volume={102},
  pages={103538},
  year={2025},
  publisher={Elsevier}
}
</pre>

![alt text](images/image-42.png)

üïê (9) Brain tumor

- [[2024-MIDL]](https://proceedings.mlr.press/v227/wei24a/wei24a.pdf) **Mprotonet: A case-based interpretable model for brain tumor classification with 3d multi-parametric magnetic resonance imaging** [:octocat:](https://github.com/aywi/mprotonet)

<pre>
@inproceedings{wei2024mprotonet,
  title={Mprotonet: A case-based interpretable model for brain tumor classification with 3d multi-parametric magnetic resonance imaging},
  author={Wei, Yuanyuan and Tam, Roger and Tang, Xiaoying},
  booktitle={Medical Imaging with Deep Learning},
  pages={1798--1812},
  year={2024},
  organization={PMLR}
}
</pre>

![alt text](images/image-43.png)

üïê (10) Cephalometric

- [[2024-MICCAI]](https://arxiv.org/pdf/2406.12577) **Cephalometric landmark detection across ages with prototypical network** [:octocat:](https://github.com/ShanghaiTech-IMPACT/CeLDA/)

<pre>
@inproceedings{wu2024cephalometric,
  title={Cephalometric landmark detection across ages with prototypical network},
  author={Wu, Han and Wang, Chong and Mei, Lanzhuju and Yang, Tong and Zhu, Min and Shen, Dinggang and Cui, Zhiming},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={155--165},
  year={2024},
  organization={Springer}
}
</pre>

![alt text](images/image-44.png)

üïê (11) Others

- [[2024-TMI]](https://ieeexplore.ieee.org/abstract/document/10378976) **A test statistic estimation-based approach for establishing self-interpretable cnn-based binary classifiers** 

<pre>
@article{sengupta2024test,
  title={A test statistic estimation-based approach for establishing self-interpretable cnn-based binary classifiers},
  author={Sengupta, Sourya and Anastasio, Mark A},
  journal={IEEE transactions on medical imaging},
  volume={43},
  number={5},
  pages={1753--1765},
  year={2024},
  publisher={IEEE}
}
</pre>

![alt text](images/image-45.png)

- [[2025-JBHI]](https://ieeexplore.ieee.org/abstract/document/10856378) **FeaInfNet: Diagnosis of Medical Images with Feature-Driven Inference and Visual Explanations** 

<pre>
@article{peng2025feainfnet,
  title={FeaInfNet: Diagnosis of Medical Images with Feature-Driven Inference and Visual Explanations},
  author={Peng, Yitao and He, Lianghua and Hu, Die and Liu, Yihang and Yang, Longzhen and Shang, Shaohua},
  journal={IEEE Journal of Biomedical and Health Informatics},
  year={2025},
  publisher={IEEE}
}
</pre>

![alt text](images/image-46.png)

## ü•∞ Star History
<div id = "s5"></div>

[![Star History Chart](https://api.star-history.com/svg?repos=BeistMedAI/Paper-List-for-Prototypical-Learning&type=Timeline)](https://www.star-history.com/#BeistMedAI/Paper-List-for-Prototypical-Learning&Timeline)